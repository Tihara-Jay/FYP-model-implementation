{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tihara-Jay/FYP-model-implementation/blob/main/Fine_tuning_of_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGMf0ePJdqMO"
      },
      "source": [
        "spam - 1 , ham - 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkz0Rlqfd326"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Flatten, Activation, BatchNormalization, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV3mC4fnj7Hw"
      },
      "source": [
        "Data preprocessing to make the data suitable to be passed into the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glfBglLHmFQl",
        "outputId": "8ce07e56-e1df-4331-f8ae-1366273bcac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwNDImkFdctD"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/FYP/Dataset/Phishing'\n",
        "ham_dir = '/content/drive/MyDrive/FYP/Dataset/Phishing/Ham'\n",
        "spam_dir = '/content/drive/MyDrive/FYP/Dataset/Phishing/Spam'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWBpy-GvdkFC",
        "outputId": "37d4c5dc-2331-46a0-bd2f-4f4e8c2be7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of spam images in spam_dir: 740\n",
            "Number of ham images in ham_dir: 740\n"
          ]
        }
      ],
      "source": [
        "spam_files = os.listdir(spam_dir)\n",
        "num_spam_files = len(spam_files)\n",
        "\n",
        "ham_files = os.listdir(ham_dir)\n",
        "num_ham_files = len(ham_files)\n",
        "\n",
        "print(\"Number of spam images in spam_dir:\", num_spam_files)\n",
        "print(\"Number of ham images in ham_dir:\", num_ham_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wNYquj1CFOY"
      },
      "outputs": [],
      "source": [
        "ham_dir = '/content/drive/MyDrive/FYP/Dataset/Phishing/Ham'\n",
        "spam_dir ='/content/drive/MyDrive/FYP/Dataset/Phishing/Spam'\n",
        "model_dir = '/content/drive/MyDrive/FYP/Dataset/Phishing/Model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLdMBmZCFipl"
      },
      "outputs": [],
      "source": [
        "train_dir = model_dir + '/train'\n",
        "test_dir = model_dir + '/test'\n",
        "validation_dir = model_dir + '/validation'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GipfdU_7r3L"
      },
      "source": [
        "Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNx4rVZZGzaH"
      },
      "outputs": [],
      "source": [
        "trainAug = ImageDataGenerator (\n",
        "  rotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "#Initializaing the validation/testing data augmentation object (to which the mean subtraction will be added to)\n",
        "valAug = ImageDataGenerator()\n",
        "\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the mean subtraction value for each of the data augmentation objects\n",
        "\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAllndnLVSGY",
        "outputId": "c9b1c8c2-68e3-46ee-903e-d2b5c13367c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1184 images belonging to 2 classes.\n",
            "Found 148 images belonging to 2 classes.\n",
            "Found 148 images belonging to 2 classes.\n",
            "Number of images: 1184\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\ttrain_dir,\n",
        "\tclass_mode=\"binary\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size = BATCH_SIZE)\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tvalidation_dir,\n",
        "\tclass_mode=\"binary\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size= BATCH_SIZE)\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "\ttest_dir,\n",
        "\tclass_mode=\"binary\",\n",
        "\ttarget_size=(224, 224),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size= BATCH_SIZE)\n",
        "num_images = trainGen.n\n",
        "print(\"Number of images:\", num_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY5ofIIYLdY2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(headModel)\n",
        "headModel = Dropout(0.3)(headModel)\n",
        "headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
        "# placing the head FC model on top of the base model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpFTF311c76O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493ffd14-677b-43b2-cd27-d2789123a6ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "baseModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UHjeehNLtP"
      },
      "outputs": [],
      "source": [
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLVQndalWLDR",
        "outputId": "d9db5053-f1ec-4675-d644-55bfeb7b295c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1184\n",
            "148\n",
            "148\n"
          ]
        }
      ],
      "source": [
        "from imutils import paths\n",
        "totalTrain = len(list(paths.list_images(train_dir)))\n",
        "totalVal = len(list(paths.list_images(validation_dir)))\n",
        "totalTest = len(list(paths.list_images(test_dir)))\n",
        "print(totalTrain)\n",
        "print(totalVal)\n",
        "print(totalTest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09p3rHW9iWbx"
      },
      "source": [
        "steps per epoch = total number of samples / batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUjWif5pwpU3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lr_schedule = ReduceLROnPlateau(factor=0.1, patience=4, verbose=1)"
      ],
      "metadata": {
        "id": "2VtN8dTS0JAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "metadata": {
        "id": "zfgu5rxqcqX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              save_weights_only=True,\n",
        "                              save_best_only=True,\n",
        "                              verbose=1)"
      ],
      "metadata": {
        "id": "ha6qVn-ac3nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFOjmAwlRV79",
        "outputId": "0f979188-982b-4070-d93b-d14acdac01b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training head...\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 5.7393 - accuracy: 0.5861 \n",
            "Epoch 1: val_loss improved from inf to 3.55400, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 749s 20s/step - loss: 5.7393 - accuracy: 0.5861 - val_loss: 3.5540 - val_accuracy: 0.6406 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 2.9806 - accuracy: 0.6334 \n",
            "Epoch 2: val_loss improved from 3.55400 to 2.51601, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 753s 20s/step - loss: 2.9806 - accuracy: 0.6334 - val_loss: 2.5160 - val_accuracy: 0.5938 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 2.0849 - accuracy: 0.6495 \n",
            "Epoch 3: val_loss improved from 2.51601 to 1.66076, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 756s 20s/step - loss: 2.0849 - accuracy: 0.6495 - val_loss: 1.6608 - val_accuracy: 0.6406 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.4227 - accuracy: 0.6706 \n",
            "Epoch 4: val_loss improved from 1.66076 to 1.48520, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 762s 20s/step - loss: 1.4227 - accuracy: 0.6706 - val_loss: 1.4852 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.2253 - accuracy: 0.6765 \n",
            "Epoch 5: val_loss improved from 1.48520 to 1.31640, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 764s 21s/step - loss: 1.2253 - accuracy: 0.6765 - val_loss: 1.3164 - val_accuracy: 0.6484 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.7086 \n",
            "Epoch 6: val_loss improved from 1.31640 to 1.19642, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 739s 20s/step - loss: 1.0743 - accuracy: 0.7086 - val_loss: 1.1964 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.7027 \n",
            "Epoch 7: val_loss improved from 1.19642 to 1.11303, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 744s 20s/step - loss: 1.0655 - accuracy: 0.7027 - val_loss: 1.1130 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.0185 - accuracy: 0.7255 \n",
            "Epoch 8: val_loss did not improve from 1.11303\n",
            "37/37 [==============================] - 739s 20s/step - loss: 1.0185 - accuracy: 0.7255 - val_loss: 1.1501 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 1.0194 - accuracy: 0.7111 \n",
            "Epoch 9: val_loss improved from 1.11303 to 1.08004, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 746s 20s/step - loss: 1.0194 - accuracy: 0.7111 - val_loss: 1.0800 - val_accuracy: 0.6719 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9682 - accuracy: 0.7441 \n",
            "Epoch 10: val_loss improved from 1.08004 to 1.05414, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 754s 20s/step - loss: 0.9682 - accuracy: 0.7441 - val_loss: 1.0541 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9719 - accuracy: 0.7458 \n",
            "Epoch 11: val_loss improved from 1.05414 to 1.00362, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 732s 20s/step - loss: 0.9719 - accuracy: 0.7458 - val_loss: 1.0036 - val_accuracy: 0.7656 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9218 - accuracy: 0.7669 \n",
            "Epoch 12: val_loss improved from 1.00362 to 0.99578, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 722s 19s/step - loss: 0.9218 - accuracy: 0.7669 - val_loss: 0.9958 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9187 - accuracy: 0.7686 \n",
            "Epoch 13: val_loss did not improve from 0.99578\n",
            "37/37 [==============================] - 738s 20s/step - loss: 0.9187 - accuracy: 0.7686 - val_loss: 1.1337 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.7829 \n",
            "Epoch 14: val_loss did not improve from 0.99578\n",
            "37/37 [==============================] - 737s 20s/step - loss: 0.8964 - accuracy: 0.7829 - val_loss: 1.0557 - val_accuracy: 0.7656 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8816 - accuracy: 0.8117 \n",
            "Epoch 15: val_loss did not improve from 0.99578\n",
            "37/37 [==============================] - 740s 20s/step - loss: 0.8816 - accuracy: 0.8117 - val_loss: 1.1050 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.9015 - accuracy: 0.7880 \n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.99578\n",
            "37/37 [==============================] - 740s 20s/step - loss: 0.9015 - accuracy: 0.7880 - val_loss: 1.0824 - val_accuracy: 0.7266 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.8721 - accuracy: 0.7931 \n",
            "Epoch 17: val_loss did not improve from 0.99578\n",
            "37/37 [==============================] - 720s 19s/step - loss: 0.8721 - accuracy: 0.7931 - val_loss: 1.0824 - val_accuracy: 0.7188 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate= 1e-4),metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Training head...\")\n",
        "H = model.fit(\n",
        "\tx=trainGen,\n",
        "\tsteps_per_epoch= totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=  totalVal // BATCH_SIZE,\n",
        "\tepochs=50,\n",
        "\tcallbacks=[early_stopping, lr_schedule, cp_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISBT0RM6XDxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97576aad-cf72-4009-f452-ddc98a8df3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/FYP/Implementation/Attempt1/21_03_vgg16_head.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/FYP/Implementation/Attempt1/head_model.h5')"
      ],
      "metadata": {
        "id": "B5C-ev34r5ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mk4HHqWlULm",
        "outputId": "50bb6aa7-4fa4-47ec-b5b9-3a0fc00edb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.0341585874557495\n",
            "Test Accuracy: 0.75\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(testGen, verbose=0)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yiJNPGHxt2k"
      },
      "source": [
        "https://pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPvg1kD-1c2V"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_training(H, N):\n",
        "    # construct a plot that plots the training history\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbhzJyxEpb0p"
      },
      "source": [
        "Unfreezing the final set of conv layers in the initial base model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainGen.reset()\n",
        "valGen.reset()\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[-8:]:\n",
        "\tlayer.trainable = True\n",
        "\n",
        "for layer in model.layers:\n",
        "\tprint(\"{}: {}\".format(layer, layer.trainable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9REifJLcYe0",
        "outputId": "dc633929-9483-46ef-f389-e06f9182e1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.engine.input_layer.InputLayer object at 0x7c2980171600>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297fcd9960>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297fcda0e0>: False\n",
            "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7c297fcdb070>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297fcdb6d0>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297fcdbf10>: False\n",
            "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7c297e3fcf10>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297fcdb520>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e3fdc00>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e3fe710>: False\n",
            "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7c297e3ff7c0>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e3ffd90>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e3fc4f0>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e4180a0>: False\n",
            "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7c297e41a230>: False\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e41aaa0>: True\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e4198d0>: True\n",
            "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x7c297e41be50>: True\n",
            "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7c297dd14160>: True\n",
            "<keras.src.layers.reshaping.flatten.Flatten object at 0x7c2980170dc0>: True\n",
            "<keras.src.layers.core.dense.Dense object at 0x7c297dd163e0>: True\n",
            "<keras.src.layers.regularization.dropout.Dropout object at 0x7c297dd16f50>: True\n",
            "<keras.src.layers.core.dense.Dense object at 0x7c297e41a650>: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpE3OdQ7po_I",
        "outputId": "aee4391d-c59b-41f3-b2ed-1c44ded91b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.6562\n",
            "Epoch 1: val_loss did not improve from 0.59088\n",
            "37/37 [==============================] - 42s 1s/step - loss: 0.7448 - accuracy: 0.6562 - val_loss: 0.6158 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.6486\n",
            "Epoch 2: val_loss did not improve from 0.59088\n",
            "37/37 [==============================] - 40s 1s/step - loss: 0.6386 - accuracy: 0.6486 - val_loss: 0.7606 - val_accuracy: 0.6406 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.6664\n",
            "Epoch 3: val_loss did not improve from 0.59088\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.6342 - accuracy: 0.6664 - val_loss: 0.6168 - val_accuracy: 0.7109 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.6596\n",
            "Epoch 4: val_loss did not improve from 0.59088\n",
            "37/37 [==============================] - 40s 1s/step - loss: 0.6263 - accuracy: 0.6596 - val_loss: 0.6188 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.7035\n",
            "Epoch 5: val_loss improved from 0.59088 to 0.57247, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.5845 - accuracy: 0.7035 - val_loss: 0.5725 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.7323\n",
            "Epoch 6: val_loss did not improve from 0.57247\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.5572 - accuracy: 0.7323 - val_loss: 0.6337 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.5510 - accuracy: 0.7297\n",
            "Epoch 7: val_loss did not improve from 0.57247\n",
            "37/37 [==============================] - 37s 1s/step - loss: 0.5510 - accuracy: 0.7297 - val_loss: 0.6198 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7382\n",
            "Epoch 8: val_loss did not improve from 0.57247\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.5586 - accuracy: 0.7382 - val_loss: 0.7347 - val_accuracy: 0.6406 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.7432\n",
            "Epoch 9: val_loss improved from 0.57247 to 0.56913, saving model to /content/drive/MyDrive/FYP/Implementation/Attempt1/Checkpoints\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.5171 - accuracy: 0.7432 - val_loss: 0.5691 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.7753\n",
            "Epoch 10: val_loss did not improve from 0.56913\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.4907 - accuracy: 0.7753 - val_loss: 0.5996 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7787\n",
            "Epoch 11: val_loss did not improve from 0.56913\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.4846 - accuracy: 0.7787 - val_loss: 0.6161 - val_accuracy: 0.7109 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.7804\n",
            "Epoch 12: val_loss did not improve from 0.56913\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.4544 - accuracy: 0.7804 - val_loss: 0.6137 - val_accuracy: 0.6641 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.7855\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.56913\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.4734 - accuracy: 0.7855 - val_loss: 0.6221 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.7905\n",
            "Epoch 14: val_loss did not improve from 0.56913\n",
            "37/37 [==============================] - 40s 1s/step - loss: 0.4495 - accuracy: 0.7905 - val_loss: 0.6202 - val_accuracy: 0.6797 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate= 1e-4), metrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit(\n",
        "\tx=trainGen,\n",
        "\tsteps_per_epoch = totalTrain // BATCH_SIZE,\n",
        "\tvalidation_data = valGen,\n",
        "\tvalidation_steps =  totalVal // BATCH_SIZE,\n",
        "\tepochs=50,\n",
        "\tcallbacks=[early_stopping, lr_schedule,cp_callback ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/FYP/Implementation/Attempt1/Accuracy/bat_VGG16_finetune.h5')"
      ],
      "metadata": {
        "id": "mALCdoBkuIEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TXzHAXwtbcM",
        "outputId": "ec369a77-46ff-4669-d805-f4064354b9c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 400ms/step - loss: 0.4894 - accuracy: 0.7635\n",
            "Test Loss: 0.4893653988838196\n",
            "Test Accuracy: 0.7635135054588318\n"
          ]
        }
      ],
      "source": [
        "testGen.reset()\n",
        "test_loss, test_accuracy = model.evaluate(testGen, verbose=1)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4j_S2mkuFWf",
        "outputId": "77965317-c4ff-4754-87d8-d382d5dc7dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21137729 (80.63 MB)\n",
            "Trainable params: 13502465 (51.51 MB)\n",
            "Non-trainable params: 7635264 (29.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/FYP/PSPD_Submission_20200601_w1833519/Demo_Images/Non_spam.jpeg'"
      ],
      "metadata": {
        "id": "HtbGhONKfBLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img = image.load_img(image_path, target_size=(224, 224))  # Resize the image to match model input size\n",
        "img_array = image.img_to_array(img)  # Convert image to numpy array\n",
        "img_array = np.expand_dims(img_array, axis=0)"
      ],
      "metadata": {
        "id": "Pf75OscXgC4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(img_array)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvBnQl2cgKSf",
        "outputId": "314302f3-34b4-4272-94c1-b706311314c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "[[0.00035218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "if predictions > threshold:\n",
        "    print(\"SPAM\")\n",
        "else:\n",
        "    print(\"HAM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-D0rNuVhUGP",
        "outputId": "504cb60e-502e-4609-b662-454e7f37a773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "testGen.reset()\n",
        "predictions = model.predict(testGen)\n",
        "\n",
        "predicted_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "true_labels = testGen.classes\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc6F_mbNjH2g",
        "outputId": "f3935a38-e11a-4367-c0bd-cf0b4c736a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 4s 583ms/step\n",
            "Accuracy: 0.75\n",
            "Precision: 0.7466666666666667\n",
            "Recall: 0.7567567567567568\n",
            "F1 Score: 0.7516778523489932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/FYP/Implementation/Attempt1/Accuracy/checkpts_bat_VGG16_finetune.h5')"
      ],
      "metadata": {
        "id": "SnYP2PX1gLVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPREFEucE6YjUhg5Qj7qpnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}